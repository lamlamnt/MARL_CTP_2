#Cmds to run to get learning curve + prop 0.4 data
#1 critic - individual - constant
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_2_agents_1_critic_individual" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 1 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

#1 critic - team - constant
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_2_agents_1_critic_team" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

#1 critic - mix at 0.5 - no decay
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_2_agents_1_critic_mixed_no_decay" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.5 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

#2 critic linear decay starting from 0.28
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_2_agents_2_critic_decay" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.28 --anneal_individual_reward_weight "linear" --num_critic_values 2 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

#1 critic best 
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_2_agents_1_critic_decay_best" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.28 --anneal_individual_reward_weight "linear" --num_critic_values 1 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

#1 critic - best prop 0.4 
python main.py --n_node 20 --n_agent 2 --time_steps 25000000 --network_type "Densenet_Same" --log_directory "experiment_20_node_2_agents_prop_0.4_best" --graph_mode "load" --num_steps_before_update 5500 --graph_identifier "normalized_node_20_agent_2_prop_0.4" --prop_stoch 0.4 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.28 --anneal_individual_reward_weight "linear" --num_critic_values 1 --clip_eps 0.115 --ent_coeff 0.08 --vf_coeff 0.18 --reward_fail_to_service_goal_larger_index -0.4 --reward_exceed_horizon -3 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001

