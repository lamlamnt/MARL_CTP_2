#Haven't decided whether to do across 1 run or 2 runs yet
#1 critic - individual - constant
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_4_agents_1_critic_individual" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 1 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_nodes_4_agents_1_critic_individual $DATA/MARL_CTP_2/ARC

#1 critic - team - constant
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_4_agents_1_critic_team" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_nodes_4_agents_1_critic_team $DATA/MARL_CTP_2/ARC

#1 critic - mix at 0.5 - no decay
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_4_agents_1_critic_mixed_no_decay" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.5 --anneal_individual_reward_weight "constant" --num_critic_values 1 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_nodes_4_agents_1_critic_mixed_no_decay $DATA/MARL_CTP_2/ARC

#2 critic linear decay starting from 0.5
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_4_agents_2_critic_decay" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.5 --anneal_individual_reward_weight "linear" --num_critic_values 2 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_nodes_4_agents_2_critic_decay $DATA/MARL_CTP_2/ARC

#1 critic best 
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_nodes_4_agents_1_critic_decay_best" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.8" --prop_stoch 0.8 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.5 --anneal_individual_reward_weight "linear" --num_critic_values 1 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_nodes_4_agents_1_critic_decay_best $DATA/MARL_CTP_2/ARC

#1 critic - best prop 0.4 
srun python main.py --n_node 20 --n_agent 4 --time_steps 22000000 --network_type "Densenet_Same" --log_directory "experiment_20_node_4_agents_prop_0.4_best" --graph_mode "load" --num_steps_before_update 3000 --graph_identifier "normalized_node_20_agent_4_prop_0.4" --prop_stoch 0.4 --num_stored_graphs 30000 --factor_inference_timesteps 2000 --individual_reward_weight 0.5 --anneal_individual_reward_weight "linear" --num_critic_values 1 --clip_eps 0.0765 --ent_coeff 0.218 --vf_coeff 0.16 --reward_fail_to_service_goal_larger_index -0.77 --reward_exceed_horizon -4 --factor_testing_timesteps 200 --num_update_epochs 6 --deterministic_inference_policy True --optimizer_norm_clip 4.0 --densenet_bn_size 4 --densenet_growth_rate 40 --learning_rate 0.001
rsync -av --exclude=input --exclude=bin ./Logs/experiment_20_node_4_agents_prop_0.4_best $DATA/MARL_CTP_2/ARC

